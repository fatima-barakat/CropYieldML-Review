{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5552c93d",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This notebook prepares the cleaned crop yield dataset for machine learning models.\n",
    "It focuses on handling missing values, encoding categorical variables, scaling numeric\n",
    "features, and constructing the final feature matrix and target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c6bb2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pc-msi\\\\Desktop\\\\CropYieldML-Review-1\\\\notebooks'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe7ff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_exploration.ipynb',\n",
       " '02_feature_engineering.ipynb',\n",
       " '03_baseline_models.ipynb',\n",
       " '04_model_comparison.ipynb']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "734b49b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed', 'raw', 'README.md']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea44fb",
   "metadata": {},
   "source": [
    "## Load Cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "373c8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56717 entries, 0 to 56716\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   domain_code                    56717 non-null  int64  \n",
      " 1   domain                         56717 non-null  object \n",
      " 2   area_code                      56717 non-null  int64  \n",
      " 3   area                           56717 non-null  object \n",
      " 4   element_code                   56717 non-null  int64  \n",
      " 5   element                        56717 non-null  object \n",
      " 6   item_code                      56717 non-null  int64  \n",
      " 7   item                           56717 non-null  object \n",
      " 8   year_code                      56717 non-null  int64  \n",
      " 9   year                           56717 non-null  int64  \n",
      " 10  unit                           56717 non-null  object \n",
      " 11  yield_value                    56717 non-null  int64  \n",
      " 12  average_rain_fall_mm_per_year  25385 non-null  float64\n",
      " 13  avg_temp                       32210 non-null  float64\n",
      " 14  pesticide_value                0 non-null      float64\n",
      " 15  domain_code_code               56717 non-null  int64  \n",
      " 16  unit_code                      56717 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../processed/df_merged_clean.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d0c17",
   "metadata": {},
   "source": [
    "## Define target and feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4aeb926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y = df[\"yield_value\"]\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=[\n",
    "    \"yield_value\",      # target\n",
    "    \"pesticide_value\",  # all missing\n",
    "    \"domain_code\",      # IDs/codes\n",
    "    \"domain\",           # optional, can drop\n",
    "    \"area_code\",        # ID\n",
    "    \"element_code\",     # ID\n",
    "    \"element\",          # optional\n",
    "    \"item_code\",        # ID\n",
    "    \"year_code\",        # ID\n",
    "    \"unit_code\",        # ID\n",
    "    \"unit\",             # optional\n",
    "    \"domain_code_code\"  # redundant\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d5e9d",
   "metadata": {},
   "source": [
    "## Check x columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af1dc2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area', 'item', 'year', 'average_rain_fall_mm_per_year', 'avg_temp'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671365c9",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39a985f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_rain_fall_mm_per_year    0\n",
       "avg_temp                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_cols = ['average_rain_fall_mm_per_year', 'avg_temp']\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X[num_cols] = imputer.fit_transform(X[num_cols])\n",
    "\n",
    "# Verify\n",
    "X[num_cols].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032319c",
   "metadata": {},
   "source": [
    "## Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7edca115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56717, 222)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "cat_cols = ['area', 'item']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "X_cat_encoded = encoder.fit_transform(X[cat_cols])\n",
    "\n",
    "# Check shape\n",
    "X_cat_encoded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b35754ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (56717, 225)\n"
     ]
    }
   ],
   "source": [
    "## Combine numeric and Categorical Features\n",
    "\n",
    "X_num = X.drop(columns=cat_cols).values\n",
    "X_final = np.hstack([X_num, X_cat_encoded])\n",
    "\n",
    "print(\"Final feature matrix shape:\", X_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85d40f",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d58998ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows after scaling:\n",
      "[[-1.77707006 -0.08679222 -1.297768    1.          0.        ]\n",
      " [-1.71508552 -0.08679222 -1.32403801  1.          0.        ]\n",
      " [-1.65310099 -0.08679222 -1.14014796  1.          0.        ]\n",
      " [-1.59111645 -0.08679222 -1.39880649  1.          0.        ]\n",
      " [-1.52913191 -0.08679222 -1.3644534   1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "## StandardScaler for numeric columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Numeric columns: first 3 columns (year + rainfall + temp)\n",
    "scaler = StandardScaler()\n",
    "X_final[:, :3] = scaler.fit_transform(X_final[:, :3])\n",
    "\n",
    "# Verify\n",
    "print(\"First 5 rows after scaling:\")\n",
    "print(X_final[:5, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c17c8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target Transformation \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_log = np.log1p(y.values)  # log(1 + y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c349ea1",
   "metadata": {},
   "source": [
    "## Save Final Features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b912dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete. Files saved in ../processed/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../processed\", exist_ok=True)\n",
    "\n",
    "np.save(\"../processed/X_final.npy\", X_final)\n",
    "np.save(\"../processed/y.npy\", y.values)\n",
    "np.save(\"../processed/y_log.npy\", y_log)\n",
    "\n",
    "joblib.dump(scaler, \"../processed/scaler.pkl\")\n",
    "joblib.dump(encoder, \"../processed/encoder.pkl\")\n",
    "\n",
    "print(\"Feature engineering complete. Files saved in ../processed/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
